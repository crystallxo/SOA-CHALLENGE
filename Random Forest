# Load necessary libraries
library(randomForest)
library(caret)
library(dplyr)
library(Metrics)
install.packages("")

data = read.csv("C:/Users/user/OneDrive/Documents/A UPH/SOA STUDY CASE/dam-clean (2) - data.csv")

# Median imputation for loss prop
loss_prop_clean <- na.omit(data$Loss_gf_Prop)
data$Loss_gf_Prop[is.na(data$Loss_gf_Prop)] <- median(loss_prop_clean, na.rm = TRUE)

# Median imputation for loss liab
loss_liab_clean <- na.omit(data$Loss_gf_Liab)
data$Loss_gf_Liab[is.na(data$Loss_gf_Liab)] <- median(loss_liab_clean, na.rm = TRUE)
# ^ini kmrn di ref ada typo loss gf nya

missing_rows <- data[!complete.cases(data), ]  # Show only rows with NA
print(missing_rows)
# setelah di cek, udah gada yg missing values lg

# Convert categorical variables to factors
data$Region <- as.factor(data$Region)
data$Purpose <- as.factor(data$Purpose)
data$Hazard <- as.factor(data$Hazard)
data$Assessment <- as.factor(data$Assessment)

# Define the target variable (Loss Given Failure - Property)
target_variable <- "Total.loss"  # Adjust if needed

# Split data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(data[[target_variable]], p = 0.7, list = FALSE)
# createDataPartition() (from caret package) → Splits data randomly while ensuring class distribution remains similar.

train_data <- data[train_index, ]
test_data <- data[-train_index, ]

# Train the Random Forest model
set.seed(123)
rf_model <- randomForest(as.formula(paste(target_variable, "~ .")), 
                         data = train_data, 
                         ntree = 100, 
                         mtry = 3, 
                         importance = TRUE)


# Evaluate model performance
rf_predictions <- predict(rf_model, newdata = test_data)

true_values <- test_data$Total.loss

# Compute regression metrics
mse <- mse(true_values, rf_predictions)
rmse <- rmse(true_values, rf_predictions)
mae <- mae(true_values, rf_predictions)
r2 <- cor(true_values, rf_predictions)^2  # R-squared

# Print results
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")
cat("R-squared:", r2, "\n")

####################################################################################

#compare hasil for testing and training, utk melihat ada overfitting ga
# Compute predictions on training data
train_rf_predictions <- predict(rf_model, train_data)

# Compute RMSE and R² for training data
train_rmse <- rmse(train_data$Total.loss, train_rf_predictions)
train_r2 <- cor(train_data$Total.loss, train_rf_predictions)^2

# Compute predictions on test data
test_predictions <- predict(rf_model, test_data)

# Compute RMSE and R² for test data
test_rmse <- sqrt(mean((test_data$Loss_gf_Prop - test_predictions)^2))
test_r2 <- cor(test_data$Loss_gf_Prop, test_predictions)^2

# Print results
cat("Training RMSE:", train_rmse, "\n")
cat("Training R-squared:", train_r2, "\n")
cat("Test RMSE:", rmse, "\n")
cat("Test R-squared:", r2, "\n")

############################################
